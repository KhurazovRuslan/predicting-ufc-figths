{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 15min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# STEP 1 - GET FIGHTERS' GENERAL INFO FROM UFCSTATS.COM\n",
    "\n",
    "\n",
    "# imports for webscraping\n",
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# import for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# iterating through every page with stats\n",
    "import string  \n",
    "alphabet = list(string.ascii_lowercase) # list of letters in alphabetc order\n",
    "\n",
    "pages = {letter:[] for letter in alphabet} # a dictionary with letters as keys and parsed pages as values\n",
    "\n",
    "# iterating through the list to store every parsed page in dictionary\n",
    "for letter in alphabet:\n",
    "    \n",
    "    my_url = \"http://ufcstats.com/statistics/fighters?char=\"+letter+\"&page=all\" # url of a page to parse\n",
    "    \n",
    "    # loading the page\n",
    "    uClient = uReq(my_url)  \n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    \n",
    "    \n",
    "    pages[letter].append(soup(page_html, 'html.parser'))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# creating a dictionary of fighters info from stats pages     \n",
    "fighters = {\n",
    "    \"first name\":[],\n",
    "    \"last name\":[],\n",
    "    \"nickname\":[],\n",
    "    \"link\":[],\n",
    "    \"height(ft)\":[],\n",
    "    \"weight(lb)\":[],\n",
    "    \"reach(inch)\":[],\n",
    "    \"stance\":[],\n",
    "    \"wins\":[],\n",
    "    \"losses\":[],\n",
    "    \"draws\":[],\n",
    "    \"belt\":[]\n",
    "}\n",
    "\n",
    "\n",
    "# iterating through every page, getting required info and putting it in the dictioanry\n",
    "for key,value in pages.items():\n",
    "    \n",
    "    # going through every parsed page to get stats\n",
    "    containers = value[0].findAll(\"tr\",{\"class\":\"b-statistics__table-row\"})\n",
    "    \n",
    "    # first two values doesn't contain any relevant information\n",
    "    del containers[:2]\n",
    "    \n",
    "    for container in containers:\n",
    "    \n",
    "    # filling out dictionary (values to respective keys)\n",
    "        fighters[\"first name\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[0].a.text)\n",
    "        fighters[\"last name\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[1].a.text)\n",
    "        fighters[\"nickname\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[2].a.text)\n",
    "        fighters[\"link\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[0].a['href'])\n",
    "        fighters[\"height(ft)\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[3].text.strip())\n",
    "        fighters[\"weight(lb)\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[4].text.strip())\n",
    "        fighters[\"reach(inch)\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[5].text.strip())\n",
    "        fighters[\"stance\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[6].text.strip())\n",
    "        fighters[\"wins\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[7].text.strip())\n",
    "        fighters[\"losses\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[8].text.strip())\n",
    "        fighters[\"draws\"].append(container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[9].text.strip())\n",
    "   \n",
    "    # champions have a link to belt image on the page, contenders don't have it.\n",
    "    # so if there's a link put 1 for champion in the dictionary, no link - put 0 for a contender \n",
    "        if container.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})[10].img is None:\n",
    "            fighters[\"belt\"].append(0)\n",
    "        else:\n",
    "            fighters[\"belt\"].append(1)  \n",
    "            \n",
    "            \n",
    "# creating a dataframe for later use        \n",
    "fighters_data = pd.DataFrame(data=fighters)\n",
    "\n",
    "\n",
    "# a dictionary for fighters' statistics from each fighter's personal page on ufcstats.com (will be added to fighters_data)\n",
    "fighter_stats = {\n",
    "    \"SLpM\":[],\n",
    "    \"Str. Acc\":[],\n",
    "    \"SApM\":[],\n",
    "    \"Str. Def\":[],\n",
    "    \"TD Avg\":[],\n",
    "    \"TD Acc.\":[],\n",
    "    \"TD Def\":[],\n",
    "    \"Sub. Avg\":[]\n",
    "}\n",
    "\n",
    "\n",
    "# using links to fighter's personal stats page that I got in the code above\n",
    "for link in fighters_data['link']:\n",
    "    \n",
    "    # parsing pages\n",
    "    uClient = uReq(link)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    \n",
    "    fighter_page = soup(page_html, \"html.parser\")\n",
    "    \n",
    "    # each page has tables with fighter's stats. Going through each table extracting required info\n",
    "    containers = fighter_page.findAll(\"ul\",{\"class\":\"b-list__box-list b-list__box-list_margin-top\"})\n",
    "    \n",
    "    # filling out dictionary\n",
    "    fighter_stats[\"SLpM\"].append(containers[0].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[0].text.split(':')[1].strip())\n",
    "    fighter_stats[\"Str. Acc\"].append(containers[0].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[1].text.split(':')[1].strip())\n",
    "    fighter_stats[\"SApM\"].append(containers[0].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[2].text.split(':')[1].strip())\n",
    "    fighter_stats[\"Str. Def\"].append(containers[0].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[3].text.split(':')[1].strip())\n",
    "    fighter_stats[\"TD Avg\"].append(containers[1].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[1].text.split(':')[1].strip())\n",
    "    fighter_stats[\"TD Acc.\"].append(containers[1].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[2].text.split(':')[1].strip())\n",
    "    fighter_stats[\"TD Def\"].append(containers[1].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[3].text.split(':')[1].strip())\n",
    "    fighter_stats[\"Sub. Avg\"].append(containers[1].findAll(\"li\",{\"class\":\"b-list__box-list-item b-list__box-list-item_type_block\"})[4].text.split(':')[1].strip())\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# creating new columns in fighters_data and adding scrapped information into new columns\n",
    "fighters_data[\"SLpM\"] = fighter_stats[\"SLpM\"]\n",
    "fighters_data[\"Str. Acc\"] = fighter_stats[\"Str. Acc\"]\n",
    "fighters_data[\"SApM\"] = fighter_stats[\"SApM\"]\n",
    "fighters_data[\"Str. Def\"] = fighter_stats[\"Str. Def\"]\n",
    "fighters_data[\"TD Avg\"] = fighter_stats[\"TD Avg\"]\n",
    "fighters_data[\"TD Acc.\"] = fighter_stats[\"TD Acc.\"]\n",
    "fighters_data[\"TD Def\"] = fighter_stats[\"TD Def\"]\n",
    "fighters_data[\"Sub. Avg\"] = fighter_stats[\"Sub. Avg\"]\n",
    "\n",
    "\n",
    "# saving dataframe into .csv file (will have to be updated regulary)\n",
    "fighters_data.to_csv('fighters_data.csv', index=False)\n",
    "\n",
    "\n",
    "# STEP 2 - EVERY EVENT'S GENERAL INFO FROM UFCSTATS.COM\n",
    "\n",
    "# webpage to scrap from\n",
    "my_url = \"http://ufcstats.com/statistics/events/completed?page=all\"\n",
    "\n",
    "# parsing the page\n",
    "uClient = uReq(my_url)\n",
    "page_html = uClient.read()\n",
    "fight_events = soup(page_html, \"html.parser\")\n",
    "\n",
    "# the page consists of tables with every event general info (name, date, place and link to event's stats)\n",
    "# creating a list of those tables\n",
    "containers = fight_events.findAll(\"td\",{\"class\":\"b-statistics__table-col\"})\n",
    "\n",
    "# first two items in the list don't contain any relevant information\n",
    "del containers[:2]\n",
    "\n",
    "# a dictionary for events' info\n",
    "events = {\n",
    "    \"event name\":[],\n",
    "    \"event date\":[],\n",
    "    \"event place\":[],\n",
    "    \"event link\":[]\n",
    "}\n",
    "\n",
    "\n",
    "# so every even value of the list has event's name, date and link while every odd value has event's place\n",
    "# iterating through the list of tables from the webpage to fill out dictionary\n",
    "for i in range(len(containers)):\n",
    "    \n",
    "    if i%2==0:\n",
    "        events[\"event name\"].append(containers[i].a.text.strip())\n",
    "        events[\"event date\"].append(containers[i].span.text.strip())\n",
    "        events[\"event link\"].append(containers[i].a['href'])\n",
    "    else:\n",
    "        events[\"event place\"].append(containers[i].text.strip())\n",
    "        \n",
    "# a dataframe for later use        \n",
    "events_data = pd.DataFrame(data=events)\n",
    "\n",
    "# saving dataframe into .csv file (will have to be updated regulary)\n",
    "events_data.to_csv(\"events_data.csv\", index=False)\n",
    "# Step 3 - every event's detailed fight information\n",
    "\n",
    "\n",
    "# a dictionary that will hold all the information scrapped\n",
    "fights = {\n",
    "    \"fight date\":[],\n",
    "    \"fight weightclass\":[],\n",
    "    \"win method\":[],\n",
    "    \"rounds\":[],\n",
    "    \"time\":[],\n",
    "    \"Winner\":[],\n",
    "    \"KD W\":[],\n",
    "    \"TD succeeded W\":[],\n",
    "    \"TD attempted W\":[],\n",
    "    \"TD % W\":[],\n",
    "    \"sub attempts W\":[],\n",
    "    \"pass W\":[],\n",
    "    \"str landed W\":[],\n",
    "    \"str total W\":[],\n",
    "    \"sig str landed W\":[],\n",
    "    \"sig str total W\":[],\n",
    "    \"sig str % W\":[],\n",
    "    \"dist str landed W\":[],\n",
    "    \"dist str total W\":[],\n",
    "    \"clinch str landed W\":[],\n",
    "    \"clinch str total W\":[],\n",
    "    \"ground str landed W\":[],\n",
    "    \"ground str total W\":[],\n",
    "    \"Loser\":[],\n",
    "    \"KD L\":[],\n",
    "    \"TD succeeded L\":[],\n",
    "    \"TD attempted L\":[],\n",
    "    \"TD % L\":[],\n",
    "    \"sub attempts L\":[],\n",
    "    \"pass L\":[],\n",
    "    \"str landed L\":[],\n",
    "    \"str total L\":[],\n",
    "    \"sig str landed L\":[],\n",
    "    \"sig str total L\":[],\n",
    "    \"sig str % L\":[],\n",
    "    \"dist str landed L\":[],\n",
    "    \"dist str total L\":[],\n",
    "    \"clinch str landed L\":[],\n",
    "    \"clinch str total L\":[],\n",
    "    \"ground str landed L\":[],\n",
    "    \"ground str total L\":[],\n",
    "}\n",
    "    \n",
    "\n",
    "#using links from events_data dataframe to get stats for each fight    \n",
    "for link in events_data[\"event link\"]:\n",
    "    \n",
    "    uClient = uReq(link)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    \n",
    "    #parsed webpage of the event\n",
    "    event_page = soup(page_html, \"html.parser\")\n",
    "    \n",
    "    \n",
    "    #event's every fight (general info)\n",
    "    containers = event_page.findAll(\"tr\",{\"class\":\"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\"})\n",
    "    \n",
    "    #looping through every fight to scrap general info to fill out dictionary\n",
    "    for container in containers:\n",
    "        \n",
    "        stats = container.findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})\n",
    "        \n",
    "        #stats contain every p class element of the table, p class is basically a cell of the table on the webpage\n",
    "        #some cells are split in two some not\n",
    "        #the first page has a winn/draw info of the fight. If there is a draw that cell is split in two (draw / draw)\n",
    "        #which creates additional element and makes len(stats) one element bigger. \n",
    "        #that's why if there's a 'win' in the first cell I'll delete the first element from the list (don't need that info)\n",
    "        #but if there's a 'draw' I'll delete first two elements to make the length of the list same for each iteration\n",
    "        \n",
    "        if stats[0].i.text == 'win':\n",
    "            del stats[0]\n",
    "        else:\n",
    "            del stats[0:2]\n",
    "        \n",
    "        #filling out the dictionary with scrapped information\n",
    "        fights[\"fight date\"].append(event_page.find(\"li\",{\"class\":\"b-list__box-list-item\"}).text.split(\":\")[1].strip())\n",
    "        fights[\"Winner\"].append(stats[0].a.text.strip())\n",
    "        fights[\"Loser\"].append(stats[1].a.text.strip())\n",
    "        fights[\"fight weightclass\"].append(stats[10].text.strip())\n",
    "        fights[\"win method\"].append(stats[11].text.strip())\n",
    "        fights[\"rounds\"].append(int(stats[13].text.strip()))\n",
    "        fights[\"time\"].append(stats[14].text.strip())\n",
    "        \n",
    "               \n",
    "        # parsing page with detailed fight statistics        \n",
    "        uClient_fight = uReq(container.a[\"href\"]) \n",
    "        fight_page_html = uClient_fight.read()\n",
    "        uClient_fight.close()\n",
    "        fight_page = soup(fight_page_html, \"html.parser\")\n",
    "        \n",
    "        #parsed webpage to collect more detailed fight stats\n",
    "        #there are 4 stats tables on the page. I need the first(index 0) and the third(index 2) tables\n",
    "        #sometimes there is no detailed info on fight. In this case len(fight_tables)=0\n",
    "        \n",
    "        fight_tables = fight_page.findAll(\"tbody\",{\"class\":\"b-fight-details__table-body\"})\n",
    "        \n",
    "        \n",
    "         \n",
    "        #If info for a fight is available (there're tables created on the page), execute this\n",
    "        if len(fight_tables) > 0:\n",
    "            \n",
    "            fights[\"KD W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[2].text.strip())\n",
    "            fights[\"TD succeeded W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[10].text.strip().split(\"of\")[0])\n",
    "            fights[\"TD attempted W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[10].text.strip().split(\"of\")[1])\n",
    "            fights[\"TD % W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[12].text.strip()[:-1])\n",
    "            fights[\"sub attempts W\"].append(stats[6].text.strip())\n",
    "            fights[\"pass W\"].append(stats[8].text.strip())\n",
    "            fights[\"str landed W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[8].text.strip().split(\"of\")[0])\n",
    "            fights[\"str total W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[8].text.strip().split(\"of\")[1])\n",
    "            fights[\"sig str landed W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[4].text.strip().split(\"of\")[0])\n",
    "            fights[\"sig str total W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[4].text.strip().split(\"of\")[1])\n",
    "            fights[\"sig str % W\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[6].text.strip()[:-1])\n",
    "            fights[\"dist str landed W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[12].text.strip().split(\"of\")[0])\n",
    "            fights[\"dist str total W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[12].text.strip().split(\"of\")[1])\n",
    "            fights[\"clinch str landed W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[14].text.strip().split(\"of\")[0])\n",
    "            fights[\"clinch str total W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[14].text.strip().split(\"of\")[1])\n",
    "            fights[\"ground str landed W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[16].text.strip().split(\"of\")[0])\n",
    "            fights[\"ground str total W\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[16].text.strip().split(\"of\")[1])\n",
    "            fights[\"KD L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[3].text.strip())\n",
    "            fights[\"TD succeeded L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[11].text.strip().split(\"of\")[0])\n",
    "            fights[\"TD attempted L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[11].text.strip().split(\"of\")[1])\n",
    "            fights[\"TD % L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[13].text.strip()[:-1])\n",
    "            fights[\"sub attempts L\"].append(stats[7].text.strip())\n",
    "            fights[\"pass L\"].append(stats[9].text.strip())\n",
    "            fights[\"str landed L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[9].text.strip().split(\"of\")[0])\n",
    "            fights[\"str total L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[9].text.strip().split(\"of\")[1])\n",
    "            fights[\"sig str landed L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[5].text.strip().split(\"of\")[0])\n",
    "            fights[\"sig str total L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[5].text.strip().split(\"of\")[1])\n",
    "            fights[\"sig str % L\"].append(fight_tables[0].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[7].text.strip()[:-1])\n",
    "            fights[\"dist str landed L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[13].text.strip().split(\"of\")[0])\n",
    "            fights[\"dist str total L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[13].text.strip().split(\"of\")[1])\n",
    "            fights[\"clinch str landed L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[15].text.strip().split(\"of\")[0])\n",
    "            fights[\"clinch str total L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[15].text.strip().split(\"of\")[1])\n",
    "            fights[\"ground str landed L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[17].text.strip().split(\"of\")[0])\n",
    "            fights[\"ground str total L\"].append(fight_tables[2].findAll(\"p\",{\"class\":\"b-fight-details__table-text\"})[17].text.strip().split(\"of\")[1])\n",
    "            \n",
    "        \n",
    "        #If not (no tables created on the page), execute this\n",
    "        else:\n",
    "            \n",
    "            fights[\"KD W\"].append(float(\"NaN\"))\n",
    "            fights[\"TD succeeded W\"].append(float(\"NaN\"))\n",
    "            fights[\"TD attempted W\"].append(float(\"NaN\"))\n",
    "            fights[\"TD % W\"].append(float(\"NaN\"))\n",
    "            fights[\"sub attempts W\"].append(float(\"NaN\"))\n",
    "            fights[\"pass W\"].append(float(\"NaN\"))\n",
    "            fights[\"str landed W\"].append(float(\"NaN\"))\n",
    "            fights[\"str total W\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str landed W\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str total W\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str % W\"].append(float(\"NaN\"))\n",
    "            fights[\"dist str landed W\"].append(float(\"NaN\"))\n",
    "            fights[\"dist str total W\"].append(float(\"NaN\"))\n",
    "            fights[\"clinch str landed W\"].append(float(\"NaN\"))\n",
    "            fights[\"clinch str total W\"].append(float(\"NaN\"))\n",
    "            fights[\"ground str landed W\"].append(float(\"NaN\"))\n",
    "            fights[\"ground str total W\"].append(float(\"NaN\"))\n",
    "            fights[\"KD L\"].append(float(\"NaN\"))\n",
    "            fights[\"TD succeeded L\"].append(float(\"NaN\"))\n",
    "            fights[\"TD attempted L\"].append(float(\"NaN\"))\n",
    "            fights[\"TD % L\"].append(float(\"NaN\"))\n",
    "            fights[\"sub attempts L\"].append(float(\"NaN\"))\n",
    "            fights[\"pass L\"].append(float(\"NaN\"))\n",
    "            fights[\"str landed L\"].append(float(\"NaN\"))\n",
    "            fights[\"str total L\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str landed L\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str total L\"].append(float(\"NaN\"))\n",
    "            fights[\"sig str % L\"].append(float(\"NaN\"))\n",
    "            fights[\"dist str landed L\"].append(float(\"NaN\"))\n",
    "            fights[\"dist str total L\"].append(float(\"NaN\"))\n",
    "            fights[\"clinch str landed L\"].append(float(\"NaN\"))\n",
    "            fights[\"clinch str total L\"].append(float(\"NaN\"))\n",
    "            fights[\"ground str landed L\"].append(float(\"NaN\"))\n",
    "            fights[\"ground str total L\"].append(float(\"NaN\"))\n",
    "            \n",
    "\n",
    "        \n",
    "#creating a dataframe out of dictionary        \n",
    "fights_data = pd.DataFrame(data=fights)\n",
    "\n",
    "#saving data into .csv file\n",
    "fights_data.to_csv(\"fights_data\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
